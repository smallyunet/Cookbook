# 第二部分 数据工程基本技能

## 3. 学习写代码

为什么这是重要的：如果你不会写代码，在数据工程中很多事情是做不了的，我记不清我多少次需要快速理解Java了。

这些可能是无穷尽的：

+ 从SQL数据库中写入或者快速获取一些数据
+ 试着生成消息发送到Kafka的topic
+ 理解Java Webservice的源码
+ 从HBase的key-value储存中读取计数统计

所里，我建议使用哪种语言呢？

我极度推荐Java，它无处不在！

当你进入Spark的数据处理时，你需要使用Scala。不过，在学习过Java后它就很简单了。

当然Python也是非常好的选择，它是非常多才多艺的语言。

就个人而言，我没有对Python太过深入，不过我会持续了解它。

在哪儿学习？你可以看看这个在Udemy上的Java课程：https://www.udemy.com/java-programming-tutorial-for-beginners

+ 面向对象编程
+ 什么是单元测试，并且它如何保证你的代码正常工作
+ 函数式编程
+ 如何使用构建工具，比如Maven
+ 弹性测试 （？）

我在这个播客中谈到了在实践中学习的重要性： https://anchor.fm/andreaskayy/episodes/Learning-By-Doing-Is-The-Best-Thing-Ever---PoDS-035-e25g44

## 4.熟悉Git

为什么这是重要的：写代码的一个重要问题是跟踪变化。你不太可能会维护程序的多个版本。

另一个是合作和文档，这也是非常重要的。

假设你的工作内容在一个Spark应用上，在你休假的时候你的同事需要修改你的代码。如果没有代码管理工具的话会带来很大的麻烦：

代码在哪儿？最后一次改动是什么？文档在哪儿？如何标记我们已经修改过代码？

如果你把你的代码放在Github上，你的同事就可以找到你的代码。他们也可以通过你的文档来理解代码（并且还可以在线评论）。

开发者可以获取你的代码，新建一个分支并做一些更改。假期结束后你可以检查并合并代码到你原始的代码中。到最后你仍然还是只有一个应用。

在哪里学习：在Github Guides的页面上你可以学到所有基础：https://guides.github.com/introduction/flow/

这个Github命令清单拯救了我很多次： https://www.atlassian.com/git/tutorials/atlassian-git-cheatsheet

可以关注：

+ Pull
+ Push
+ Branching
+ Forking

## 5. 敏捷开发 —— 可行

敏捷是可以快速使用需求变化的能力。

现在每个人都想要变得敏捷，大公司或小公司都在寻找“创业心态”。

很多人认为这是企业文化，也有人认为这是我们搞事情的重要过程。

这篇文章我会讲讲关于敏捷性和自主性，关于如何在你的职业生涯中融入敏捷性。

### 5.1 为什么敏捷很重要？

历史上的开发在实践中是一个很难定义的过程。你想到一些东西，指定它，然后去开发，构建起一个混乱的产品。

这是一个有点自大的过程，你要假设你已经知道顾客想要的是什么，或者是你产品的外观和每一个功能的工作原理。

问题这个世界是不会这样去运作的。

很多次需求的改变是由于内部因素。

有时候事情不会按照你的计划进行，或者一些事情的难度超出了你的预期。

你需要适应这些。

很多时候你会发现你的顾客不喜欢你构建出来的东西，需要去修改。

你需要适应这些。

这就是为什么人们跳进Scrum火车的原因，因为Scrum是敏捷开发的代名词，对吧？

### 5.2 我多年来学习敏捷规则 —— 可行

#### 5.2.1 这种方法有什么不欧婷吗？

是的，Scrum或者Google的OKR可以帮助你更加敏捷。然而，敏捷的秘诀不止在于你如何进行创造。

让我畏惧的是人们试图告诉你，敏捷是从你的头脑中开始的。问题真的在于你吗？

不是！

这几年来我得到的最大的教训就是：当你把工作外包出去的时候，敏捷性会付诸东流。

#### 5.2.2 外包的问题

我知道在纸面上外包似乎是没脑子的：开发成本和薪酬不对等。

把现有资源绑定在任务上的代价是昂贵的。如果你需要雇佣一个新的员工，代价就更大了。

问题就在于你支付钱，别人给你做东西。

你付钱给为你做事的人，这是没问题的。他需要挣钱。

他的规划是花费尽可能少的时间在你的工作上。这就是为什么需要合同、细节规划、时间表和交付日期。

他不希望花费额外的时间在你的项目上，仅仅是因为你中期改需求了。每一次计划外的更改都会花费他的时间和金钱。

如果这样的话，你还需要另一份细节规划和合同变更。

他不会在开发过程中想着产品的提高。首先是因为他没有从大局着想，其次就是因为他不想那样做。

他照别人说的做。

谁能职责他们？如果我是分包商，我也会这么做。

这听起来像是你想要的敏捷吗？

#### 5.2.3 知识为王：来自Elon Musk的一课

在公司里完成每一件事情，这就是创业公司高产的原因。不要浪费时间等别人。

如果某个东西需要改变，团队里的任何一个人都可以完成它。

遵从这一策略的卓越案例是Elon Musk。

特斯拉巨型工厂设计将原材料生产在一个地方，然后在另一个地方组装成汽车。你以为特斯拉巨型工厂为什么要这么设计？

为什么SpaceX要建造一个太空引擎？很显然有其他更老牌的公司可以为他们做到这些。

为什么Elon要在他新的隧道钻探公司购置新的隧道钻探机器？

乍一看这毫无意义！

#### 5.2.4 要如何为敏捷做准备

如果你仔细观察，一切都来源于控制力和知识。你，你的公司，你的团队，需要尽可能多的自己做一些事情。自力更生是王道。

构建你的知识体系包括团队相关的知识。当你有能力自己坐一切事情的时候，你就可以获得全部的控制权。

你可以构建电子汽车、火箭引擎或者隧道钻孔机。

不要太过依赖别人，尽可能的充实你自己。

梦想很大，JUST DO IT!

PS. 不要误会我，你仍然可以使用外包工作。只是要把小的、独立的功能部件外包出去。

### 5.3 敏捷框架

#### 5.3.1 Scrum

这是一个有趣的Scrum相关的媒体出版物，包含很多Scrum相关的细节： https://medium.com/serious-scrum

这是一个scrum引导页面，包含了很多有用的信息： https://www.scrumguides.
org/scrum-guide.html

#### 5.3.2 OKR

我个人喜欢OKR，实践很多年了。尤其对于小团队，OKR很有用。你不需要太多的开销，工作就可以完成。它有助于你集中注意力，把持大局。

我建议每个周一开一个同步回忆，说一说上周做了什么，以及本周要做的工作。

我在这个播客上讲到了这个话题： https://anchor.fm/andreaskayy/embed/episodes/Agile-Development-Is-Important-But-Please-Dont-Do-Scrum--PoDS-041-e2e2j4

这是一个来自Google的1.5小时的指南： https://youtu.be/mJB83EZtAjc
我非常喜欢这个视频。我重新观看过很多次。

### 5.4 软件工程课程

软件工程的课程是非常重要的，关于一个公司如何让上百个开发者协同工作。这是一个播客集：

（表 5.1）

**一些有趣的幻灯片：**

https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/

https://labs.spotify.com/2014/09/20/spotify-engineering-culture-part-2/

## 6. 了解计算机的工作原理

### 6.1 CPU，RAM，GPU，HDD

#### 6.2 电脑和服务器的不同

我在这个播客中讲到了计算机硬件和GPU处理相关的东西：https://anchor.fm/andreaskayy/embed/episodes/Why-the-hardware-and-the-GPU-is-super-important--PoDS-030-e23rig

## 7. 计算机网络 —— 数据传输

### 7.1 OSI模型

OSI模型描述了数据如何在网络下传输。它由从物理层开始的层组成，是如何通过网线和光纤传输数据的。

这个页面展示了OSI模型的层级以及他们是如何工作的：https://learningnetwork.
cisco.com/docs/DOC-30382

这个页面上也有：https://www.studytonight.com/computer-networks/complete-osi-model

Wikipedia页面上的内容同样非常好：https://en.wikipedia.org/wiki/OSI model

哪个协议位于哪个层？查看这个网络协议地图。不幸的是这几天很难找到它了： https://www.blackmagicboxes.com/wp-content/uploads/2016/12/Network-Protocols-Map-Poster.jpg

### 7.2 子网划分

这里有一个来自Cisco的IP地址和子网划分的向导： https://www.cisco.com/c/en/us/support/docs/ip/routing-information-protocol-rip/13788-3.html

一个子网划分计算器：https://www.calculator.net/ip-subnet-calculator.html

### 7.3 第三层交换机

### 7.4 路由器

### 7.5 防火墙

我在这个播客中谈到了关于网络基础设施和技术的内容： https://anchor.
fm/andreaskayy/embed/episodes/IT-Networking-Infrastructure-and-Linux-031-PoDS-e242bh

## 8. 安全和隐私

### 8.1 公用的SSL & 私钥证书

### 8.2 什么是证书颁发机构

### 8.3 JSON网络令牌

看这个Wiki页面：https://en.wikipedia.org/wiki/JSON_Web_Token

### 8.4 GDPR条例

### 8.5 在设计上保护隐私

## 9. Linux

Linux是非常重要的内容，需要去学习。很多大数据工具或者NoSQL数据库就是运行在Linux上的。

时不时你会需要通过操作系统修改一些东西。尤其你运行了一些基础设施作为服务的解决方案，比如Cloudera CDH、Hortonworks或者一个MapReduce Hadoop分布式系统。

### 9.1 系统基础

显示左右历史命令：

```shell
history | grep docker
```

### 9.2 Shell脚本

### 9.3 定时任务

定时任务在Linux工作中是非常重要的去运行简单作业的工具。我保证你会需要这个。这里有三个向导：

https://linuxconfig.org/linux-crontab-reference-guide

https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/

以及Wikipedia上的教程，内容非常好: https://en.wikipedia.org/wiki/Cron

专业小贴士：不要忘记用空行或者注释行结束你的定时任务配置文件，否则定时任务将不起作用。

### 9.4 数据包管理

这个播客第二部分的内容是关于Linux的：https://anchor.fm/andreaskayy/embed/
episodes/IT-Networking-Infrastructure-and-Linux-031-PoDS-e242bh

## 10. 云服务

### 10.1 IaaS vs PaaS vs SaaS

这个播客可以帮助你理解他们的不同，以及如何去选择你使用哪一个。

（表 10.1）

### 10.2 AWS, Azure, IBM, Google Cloud基础

### 10.3 Could vs On-Premises

（表 10.2）

### 10.4 安全

播客上关于云的几个想法：https://anchor.fm/andreaskayy/embed/episodes/Dont-Be-Arrogant-The-Cloud-is-Safer-Then-Your-On-Premise-e16k9s

### 混合云

混合云结合了on-premises和云部署平台

这是一个Google Anthos的例子：https://cloud.google.com/anthos/

## 11. 安全区设计

### 11.1 如何保护多层级的应用程序

（不同区域的UI，然后时SQL数据库）

### 11.2 使用Kerberos的集群安全性

我在这个播客中谈到了关于安全区的设计，和lambda架构：https://anchor.fm/andreaskayy/embed/episodes/How-to-Design-Security-Zones-and-Lambda-Architecture--PoDS-032-e248q2

### 11.3 Kerberos票证

## 12. 大数据

### 12.1 什么是大数据？数据科学和数据分析的区别是什么？

我在这个播客中讲了它们的不同：https://anchor.fm/andreaskayy/embed/episodes/BI-vs-Data-Science-vs-Big-Data-e199hq

### 12.2 大数据的4V —— 可用

这完全是一种误解，体量（Volume）仅仅只是4V的一个部分，大数据的4V包括：体量（Volume）、速度（Verlcity）、多样性（Variety）和准确性（Veracity）。

**体量**就是大小，你有多少数据。

**速度**就是你可以用多快的速度获得数据。

在指定时间内可以有多少数据被处理或者进入系统，这就是流式数据和实时处理的全部概念所在。

**多样性**是第三部分，它意味着数据是不同的，你有很多不同类型的数据结构。

比如CSV文件、PDFs，或者你有一些数据在XML上，有一些JSON日志，又或是key-value形式储存的数据。

关于来自不同数据源的多种数据类型，你基本上希望都放在一起。所有的一切都要基于数据分析。

**准确性**是第四个，也是非常非常难的一个。大数据的问题就在于，它很不可靠。

你不能真的相信数据，尤其是你的数据来自物联网。设备使用传感器测量温度、压力和加速度。

你不能总是百分百相信测量出来的数据是对的。

当你的数据来自SAP实例，并且是手动创建的数据，这通常会给你带来问题。你知道我们人类不擅长输入这些东西。

每个人的表达方式都不同。我们还可能会有失误，甚至是拼写错误，这对于数据分析来说是非常难以解决的问题。

我在这个播客中有讲关于4V的话题：https://anchor.fm/andreaskayy/embed/episodes/4-Vs-Of-Big-Data-Are-Enough-e1h2ra

### 12.3 为什么是大数据？

我一直强调的4个V是很重要的，它们会给你一个大致的方向。

这里有一个更重要的问题：灾难性的成功。

我说的灾难性的成功是指，你的项目或者你的创业公司，增长速度远超过你的预期。指数增长是任何人都想要的。

因为伴随指数性增长而来的是钱。从一开始很小到现在快速增长到很大，传统的曲线是：

1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384....BOOM!

想想，它一开始很小，很慢，但是变得非常大非常快。

你获得了很多用户愿意花钱使用你提供的服务，平台或者其他什么的都好。如果你的系统不具备弹性处理如此大量数据的能力，系统将面临崩溃。

这是灾难性的成功。你非常成功增值非常快，但是不能够满足需求了。然后你失败了。

现在你可以一边走一边弥补，你能够预见你的系统将会在几周或者几个月后无法继续工作。

#### 12.3.1 每件事情都做好计划

事情往往发生的很快以致你不能够及时做出反应。这是你面对公司需求进行计划和分析的一种必要的潜力。

然后你需要决定，你是否会面对真正的大数据。

你需要决定是否使用大数据工具，这意味着，当你将基础架构概念化时，将重心放在大数据工具上看起来是可笑的。

但是长远来看，它将会帮助你。好的计划可以解决掉很多问题，尤其是关于流数据处理和实时数据处理。

#### 12.3.2 ETL的问题

一种典型的旧学校的平台往往像图片这样部署。设备通过API上传将要储存在SQL数据库中的数据，外部分析工具正在查询数据并且上传结果到SQL数据库中。用户使用用户界面来展示从数据库中查出的数据。

（图 12.1）

当前端从SQL数据库请求数据时，会有三个步骤：

数据库返回所有需要的行，提取出来的数据会进行一些转换，比如按照时间排序或者其他你想要的方式。

提取出来的数据通过传输加载到用户界面上，现在在图表上。随着存储的数据量激增，ETL处理开始出现问题。

分析大量数据可能需要一整天、一周、一个月，甚至更久。数据集可能非常大，会超过100GB、TB，这意味着十亿甚至万亿行数据。

这时ETL处理数据就会需要越来越长的时间，很快ETL将不能承载压力，直至无法分发结果给分析系统。

传统的解决方案是提高数据库的性能，这叫增速。

#### 12.3.3 向上扩展

为了让系统拥有更高的性能，增加ETL的处理速度，管理员需要更好的硬件：

使用更快的磁盘在物理上提高读写速度以提高性能。增加RAM内存和缓存。内存中存在的数据不必再由低速磁盘驱动读取。使用更快的CPU增加数据交换的速度。增加或优化网络性能，使用更快的速度将数据传输到前端，分析系统的向上扩展非常容易。

（图 12.2）

但是随着指数增长，你很快又会面临同样的问题。这时你无法再简单的通过提高硬件设备的性能来为系统提速，因为你已经使用了最好的硬件设备，或者你无法承担更加昂贵的硬件设备。

下一步你可以做的是扩大规模。

#### 12.3.4 向外扩展

向外扩展与向上扩展相反，它的目标不是构建更大的系统，而是使用更多小系统分散负载。

最简单的扩展SQL数据库的方式就是使用存储区域网络（SAN，Storage Area Network）去储存数据。你可以使用至多8个SQL服务器，将他们连接起来共同处理请求。这样负载就被分散到了8台服务器上。

（图 12.3）

这种方式最主要的缺点是，因为储存内容是共享的，所以它只能够作为读库。而且必须定时同步
，比如每天一次。要更新数据，SQL服务器必须从集群中分离，这样，就必须有一台服务器专门用于读写以刷新数据。如果需要上载大量数据，这个过程可能需要很长时间。

微软MSDN的页面上有很多关于扩展SQL数据库的配置说明、

我故意没有详细讲述向外扩展的解决方案。这里我想说的是，虽然这种方式可以扩展SQL数据库，但它是很复杂的。

没有完美的解决方案，每一种选项都有优缺点。主要的问题是你需要管理措施来实现和维护一个向外扩展的系统。

#### 12.3.5 请不要来大数据

如果你没有遇到系统的扩展问题，请不要使用大数据工具。

大数据的成本是很高的，一个Hadoop集群可以需要至少5个实例，甚至更多。

相信我这些东西值很多钱。

尤其当你在讨论维护和开发顶级的大数据工具时。

如果你不需要它，那它对于你完全没有意义。

话句话说，如果你真的需要大数据工具，它将会救你一命 :)

## 13. 我的大数据平台蓝图

前段时间我创建了一个简单的模块化的大数据平台蓝图，它基于我在这个领域内的见识，以及我通过网络阅读的很多技术博客。

今天我要把它分享给你。

为什么我相信它对你是超级有用的？

因为，不像其他蓝图，他没有聚焦在技术上，而是基于4个公用的大数据设计模式。

我的蓝图允许你创建出完全满足你需求的大数据平台，创建出的这个平台可以给数据科学家使用，帮助他们发现新的东西。

它可以让你完美的处理大数据，并且让你可以做出大数据驱动的决策。

蓝图将关注4个关键领域：摄入，存储，分析，展示。

（图 13.1）

这样去分割平台，让它变成一个使用松散接口联系起来的模块化的平台。

为什么平台的模块化这么重要？

如果你的平台不是模块化的，最终你会得到一些固定的或是难以修改的东西。这意味着你不能根据公司的需求调整你的平台。

正因为模块化，你可以在你需要的时候把任意组件换掉。

现在，让我们了解更多，关于每一个关键领域。

### 13.1 摄入

摄入是指从数据源获得数据，可以为之后的阶段做准备。数据源是任意的，比如推特、服务器日志或者物联网设备。

数据源向你的接口发送数据，你的接口就会将数据保存在一个暂时的存储器中。

这个临时的存储器允许其他阶段快速便捷的访问数据。

一个好的方案就是使用消息队列系统，比如Apache Kafka、RabbitMQ或者AWS Kinesis。有时人们也会针对某些应用使用缓存，像Redis。

一种好用的实践是临时存储器遵循发布-订阅模式，这样API就可以发布消息，以便分析系统可以快速消费它们。

### 13.2 分析、处理

分析阶段是真正进行数据的地方。数据分析就是形成数据流并批量处理它们。

数据流来自摄入的数据，因此是实时的，并且能够快速出分析结果。

作为最重要最核心的阶段，数据分析会访问大数据存储系统，分析系统带走大批的数据并进行分析，这种类型的数据分析叫做批处理。它将为你解决很大的问题。

想学习更多关于流和批处理可以阅读我的博客文章：How to Create New and Exciting Big Data Aided Products

数据分析和流处理不是单向处理的过程，数据分析同样会写回数据到存储系统中。

通常将分析数据写入存储系统是有意义的，它允许你将之前的分析结果和原始数据结合起来。

如果将它们结合起来进行分析，也许会有意想不到的收获。

通常广泛使用的大数据分析工具如MapReduce或AWS Elastic MapReduce、Apache Spark以及AWS lambda。

### 13.3 存储

典型的大数据存储是储存所有的数据，这有助于你从大局上进行分析。

很多数据看似无用，但最重要的是保持它，千万不要丢弃数据。

为什么不能丢弃无用的数据？

虽然它现在看起来是没用的，数据科学家可以使用数据正常分析，但是他们今后有可能会从另外的角度去进行分析，并且能够得出有趣的观点，这个时候看似无用的数据就派上用场了。

什么样的系统可以用作大数据存储？

比如Hadoop HDFS、Hbase、Amazon S3或者DynamoDB都是可以完美适应大数据存储的系统。

我的播客中提到关于使用关系型数据库还是菲关系型数据库的问题： https://anchor.fm/andreaskayy/embed/episodes/NoSQL-Vs-SQL-How-To-Choose-e12f1o

### 13.4 展示

展示数据也是非常重要的一个环节。人们需要让大数据可以去驱动决策。

这就是为什么让数据可视化非常重要，有时你会有来自不同平台的案例和项目。

你可能无法构建每一个人都满意的UI，你可以做的是让他们自己去构建自己满意的UI。

怎么做？开放API去接收数据，允许他们开发。

无论是UI还是API，数据可视化的目的都是让展示阶段可以直接访问到大数据集群中的数据，这种对数据的访问允许开发者直接去使用数据分析的结果，以构建完美的应用程序。

## 14 Lamdba架构

（表 14.1）

### 14.1 批处理

问个大问题，记得你去年的纳税申请表吗？

你打开文件夹，在房间里到处找收据。

真是有趣的事情。

当你找到所有的东西，你填好表格，把它寄出去。

制作纳税表单的过程就是一个批处理的过程。

数据进去存储器，然后分析系统从存储器中加载数据，最后输出：

（图 14.1）

批处理就是你在没有计划和计划表的时候做一些事情。

它经常用来提出大问题，或者从大局上提出见解。

批处理工作就是使用大量的数据。这些数据可能来自Hadoop HDFS等。

它们可以没有问题的储存很多数据。

批处理工作的结果很有用，不过执行处理的时间可能会很长，毕竟数据量非常大。

它可能会花费你几分钟或者几个小时的时间。

### 14.2 流处理

及时了解你的数据。

流处理允许用户基于真实数据实时的得出结论或者做出行动。和批处理相比，流处理快到飞起。

用流处理你不需要等待数个小时才能得到结果，你可以立即得到数据的分析见解。

批处理进程中，数据分析总是落后于数据存储，需要获取所有可用的数据。

流处理可以在数据存储之前得到结果，它允许系统仅仅得到数据的某一部分。

也因此，得到的数据结果有限，毕竟大的蓝图受到限制。

（图 14.2）

仅使用流分析你就可以为用户提供先进的服务了。Netflix将流处理集成到Chuckwa V2.0和新的Keystone管道中。

一个使用流处理提供先进服务的例子就是Netflix的“Trending Now”特性。

### 14.3 你应该用流处理还是批处理？

开始的时候用批处理是一个好想法，批处理是每一个大数据平台的基础。

平台便捷也意味着，可以以较低的成本运行起来。

一个批处理平台可以帮助你快速的提出大问题，它可以针对你的顾客和数据提供给你无价的见解。

随着时间的流逝，你可能渐渐的需要让数据分析变得更快，这个时候再将流处理管道嫁到你的大数据平台批处理任务中。

### 14.4 Lambda架构的替代品

#### 14.4.1 Kappa架构

#### 14.4.2 带Kudu的Kappa架构

### 14.5 为什么一个好的大数据平台是重要的

（表 14.2）

## 15 Data Warehouse vs Data Lake

## 16 Hadoop平台 —— 可行

当人们谈论大数据的时候，第一个想到的就是Hadoop，谷歌一下Hadoop，大约有28百万条信息。

看起来你需要Hadoo去做大数据，今天我会阐明为什么Hadoop如此流行。

你会看到Hadoop从一个平台演化成一个生态系统，它的设计允许很多Apache项目和第三方工具从中受益。

我将以我的观点讲述它，如果你需要学习Hadoop，如果Hadoop是适合每个人的技术。

### 16.1 Hadoop是什么

Hadoop是一个针对分布式存储和大数据分析的平台。

Hadoop有4个主要模块：Hadoop common、JHDFS、MapReduce和YARN。这些模块被编织在一起就是Hadoop如此成功的原因。

Hadoop common的包和函数是在后台运行的，所以我没有深入了解它们，它们的作用是支持Hadoop模块的工作。

（表 16.1）

### 16.2 是什么让Hadoop如此流行 —— 可行

能够储存和分析大量数据当然是好的，但是为什么Hadoop会这么流行呢？

Hadoop的核心能力是Hadoop采用的驱动，很多Apache的其他项目都在用它的核心功能。

因为很多Hadoop的边缘项目都被算入Hadoop生态系统，一个做数据存储和数据分析的系统。

为了更好的看明白这个生态系统，我画了下面这个图。它展示了生态系统中与Hadoop紧密关联的项目。

它不是一个完整的列表，还有很多我不知道的工具，也许我以后可以画一个更完整的图。

（图 16.1）

### 16.3 Hadoop生态系统组件

还记得我的大数据蓝图吗？我的蓝图包含四个部分：摄入、储存、分析和展示。

正因为Hadoop生态系统，可以让这些阶段的工作完美协同起来。

例如：

（图 16.2）

使用Kafka摄取数据，用HDFS储存数据。用Apache Sprak做数据分析，并将显示结果作为后端储存在HBase中。

一个工作系统同样需要YARN做资源管理，你同样需要Zookeeper作为配置中心去管理kafka和HBase。

你可以在下面的图中看到每一个项目都和其它项目紧密联系。

Spark实例可以直接进入Kafka消费数据，它也可以进入HDFS对数据排序或者处理储存着的数据。

它也可以向HBase写入数据，将分析结果推送到前端。

这个生态系统最酷的一点是可以轻易的构建新的功能。

想要用Spark直接把Kafka的数据存到HDFS里面？

没问题，有一个项目叫Apache Flume就是干这个事的。

我可以作为一个代理去Kafka中消费消息，你甚至不需要担心Flume中的资源管理问题。

Flume可以直接调用Hadoop的YARN资源管理。

（图 16.3）

### 16.4 Hadoop无处不在？

Hadoop虽然很强大但它不是银弹，你也不能再任何场景都去用它。

通常部署一个Hadoop集群是没有意义的，因为它可能消耗过大。Hadoop不能运行在单个服务器上。

你可能需要至少5台服务器，最好6台以上，因此对于平台初期，成本是非常高的。


一种选择是你可以使用特殊的系统，比如Cassandra、MongoDB或者其他非关系型数据库去存储数据。或者你移步去Amazon使用Amazon的简单储存服务、S3等。

猜一猜S3背后的技术是什么？是的，HDFS，这就是为什么亚马逊有和MapReduce同等弹性的MapReduce。

使用S3最大的好处是你的系统可以从小开始，当你的系统逐渐壮大时，你也不需要考虑S3扩容的问题。

### 16.5 你应该学习Hadoop吗？

是的，我非常建议你去学习一下Hadoop的工作原理以及如何使用它，就像我在这篇文章中说的，它的生态系统很大。

很多大数据项目都使用Haddoop或者使用Hadoop的接口，这样你在学习Hadoop的过程中也可以学习到很多其他大数据相关的东西。

不需要特别深入，只要知道它们怎么工作，该如何去使用它们就够了。你的主要任务是当你进入一个大数据项目时，你可以快速前进。

另外，大多数相关的额技术都是开源的，你可以无偿使用它们。

**Hadoop系统的架构是什么样子**

**Hadoop集群常用的工具是什么**

Yarn Zookeeper HDFS Oozie Flume Hive

### 16.6 如何选择Hadoop硬件

---

(暂时跳过17 ~ 19节的内容)

## 17 Docker

## 18 REST APIs

## 19 Databases

---

## 20 数据处理以及数据分析框架

### 20.1 ETL是否仍然与数据分析相关？

（表 20.1）

### 20.2 流处理



