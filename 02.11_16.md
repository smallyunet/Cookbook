# 第二部分 数据工程基本技能（第11节 ~ 第16节）

## 11. 安全区设计

### 11.1 如何保护多层级的应用程序

（不同区域的UI，然后时SQL数据库）

### 11.2 使用Kerberos的集群安全性

我在这个播客中谈到了关于安全区的设计，和lambda架构：https://anchor.fm/andreaskayy/embed/episodes/How-to-Design-Security-Zones-and-Lambda-Architecture--PoDS-032-e248q2

### 11.3 Kerberos票证

## 12. 大数据

### 12.1 什么是大数据？数据科学和数据分析的区别是什么？

我在这个播客中讲了它们的不同：https://anchor.fm/andreaskayy/embed/episodes/BI-vs-Data-Science-vs-Big-Data-e199hq

### 12.2 大数据的4V —— 可用

这完全是一种误解，体量（Volume）仅仅只是4V的一个部分，大数据的4V包括：体量（Volume）、速度（Verlcity）、多样性（Variety）和准确性（Veracity）。

**体量**就是大小，你有多少数据。

**速度**就是你可以用多快的速度获得数据。

在指定时间内可以有多少数据被处理或者进入系统，这就是流式数据和实时处理的全部概念所在。

**多样性**是第三部分，它意味着数据是不同的，你有很多不同类型的数据结构。

比如CSV文件、PDFs，或者你有一些数据在XML上，有一些JSON日志，又或是key-value形式储存的数据。

关于来自不同数据源的多种数据类型，你基本上希望都放在一起。所有的一切都要基于数据分析。

**准确性**是第四个，也是非常非常难的一个。大数据的问题就在于，它很不可靠。

你不能真的相信数据，尤其是你的数据来自物联网。设备使用传感器测量温度、压力和加速度。

你不能总是百分百相信测量出来的数据是对的。

当你的数据来自SAP实例，并且是手动创建的数据，这通常会给你带来问题。你知道我们人类不擅长输入这些东西。

每个人的表达方式都不同。我们还可能会有失误，甚至是拼写错误，这对于数据分析来说是非常难以解决的问题。

我在这个播客中有讲关于4V的话题：https://anchor.fm/andreaskayy/embed/episodes/4-Vs-Of-Big-Data-Are-Enough-e1h2ra

### 12.3 为什么是大数据？

我一直强调的4个V是很重要的，它们会给你一个大致的方向。

这里有一个更重要的问题：灾难性的成功。

我说的灾难性的成功是指，你的项目或者你的创业公司，增长速度远超过你的预期。指数增长是任何人都想要的。

因为伴随指数性增长而来的是钱。从一开始很小到现在快速增长到很大，传统的曲线是：

1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384....BOOM!

想想，它一开始很小，很慢，但是变得非常大非常快。

你获得了很多用户愿意花钱使用你提供的服务，平台或者其他什么的都好。如果你的系统不具备弹性处理如此大量数据的能力，系统将面临崩溃。

这是灾难性的成功。你非常成功增值非常快，但是不能够满足需求了。然后你失败了。

现在你可以一边走一边弥补，你能够预见你的系统将会在几周或者几个月后无法继续工作。

#### 12.3.1 每件事情都做好计划

事情往往发生的很快以致你不能够及时做出反应。这是你面对公司需求进行计划和分析的一种必要的潜力。

然后你需要决定，你是否会面对真正的大数据。

你需要决定是否使用大数据工具，这意味着，当你将基础架构概念化时，将重心放在大数据工具上看起来是可笑的。

但是长远来看，它将会帮助你。好的计划可以解决掉很多问题，尤其是关于流数据处理和实时数据处理。

#### 12.3.2 ETL的问题

一种典型的旧学校的平台往往像图片这样部署。设备通过API上传将要储存在SQL数据库中的数据，外部分析工具正在查询数据并且上传结果到SQL数据库中。用户使用用户界面来展示从数据库中查出的数据。

（图 12.1）

当前端从SQL数据库请求数据时，会有三个步骤：

数据库返回所有需要的行，提取出来的数据会进行一些转换，比如按照时间排序或者其他你想要的方式。

提取出来的数据通过传输加载到用户界面上，现在在图表上。随着存储的数据量激增，ETL处理开始出现问题。

分析大量数据可能需要一整天、一周、一个月，甚至更久。数据集可能非常大，会超过100GB、TB，这意味着十亿甚至万亿行数据。

这时ETL处理数据就会需要越来越长的时间，很快ETL将不能承载压力，直至无法分发结果给分析系统。

传统的解决方案是提高数据库的性能，这叫增速。

#### 12.3.3 向上扩展

为了让系统拥有更高的性能，增加ETL的处理速度，管理员需要更好的硬件：

使用更快的磁盘在物理上提高读写速度以提高性能。增加RAM内存和缓存。内存中存在的数据不必再由低速磁盘驱动读取。使用更快的CPU增加数据交换的速度。增加或优化网络性能，使用更快的速度将数据传输到前端，分析系统的向上扩展非常容易。

（图 12.2）

但是随着指数增长，你很快又会面临同样的问题。这时你无法再简单的通过提高硬件设备的性能来为系统提速，因为你已经使用了最好的硬件设备，或者你无法承担更加昂贵的硬件设备。

下一步你可以做的是扩大规模。

#### 12.3.4 向外扩展

向外扩展与向上扩展相反，它的目标不是构建更大的系统，而是使用更多小系统分散负载。

最简单的扩展SQL数据库的方式就是使用存储区域网络（SAN，Storage Area Network）去储存数据。你可以使用至多8个SQL服务器，将他们连接起来共同处理请求。这样负载就被分散到了8台服务器上。

（图 12.3）

这种方式最主要的缺点是，因为储存内容是共享的，所以它只能够作为读库。而且必须定时同步
，比如每天一次。要更新数据，SQL服务器必须从集群中分离，这样，就必须有一台服务器专门用于读写以刷新数据。如果需要上载大量数据，这个过程可能需要很长时间。

微软MSDN的页面上有很多关于扩展SQL数据库的配置说明、

我故意没有详细讲述向外扩展的解决方案。这里我想说的是，虽然这种方式可以扩展SQL数据库，但它是很复杂的。

没有完美的解决方案，每一种选项都有优缺点。主要的问题是你需要管理措施来实现和维护一个向外扩展的系统。

#### 12.3.5 请不要来大数据

如果你没有遇到系统的扩展问题，请不要使用大数据工具。

大数据的成本是很高的，一个Hadoop集群可以需要至少5个实例，甚至更多。

相信我这些东西值很多钱。

尤其当你在讨论维护和开发顶级的大数据工具时。

如果你不需要它，那它对于你完全没有意义。

话句话说，如果你真的需要大数据工具，它将会救你一命 :)

## 13. 我的大数据平台蓝图

前段时间我创建了一个简单的模块化的大数据平台蓝图，它基于我在这个领域内的见识，以及我通过网络阅读的很多技术博客。

今天我要把它分享给你。

为什么我相信它对你是超级有用的？

因为，不像其他蓝图，他没有聚焦在技术上，而是基于4个公用的大数据设计模式。

我的蓝图允许你创建出完全满足你需求的大数据平台，创建出的这个平台可以给数据科学家使用，帮助他们发现新的东西。

它可以让你完美的处理大数据，并且让你可以做出大数据驱动的决策。

蓝图将关注4个关键领域：摄入，存储，分析，展示。

（图 13.1）

这样去分割平台，让它变成一个使用松散接口联系起来的模块化的平台。

为什么平台的模块化这么重要？

如果你的平台不是模块化的，最终你会得到一些固定的或是难以修改的东西。这意味着你不能根据公司的需求调整你的平台。

正因为模块化，你可以在你需要的时候把任意组件换掉。

现在，让我们了解更多，关于每一个关键领域。

### 13.1 摄入

摄入是指从数据源获得数据，可以为之后的阶段做准备。数据源是任意的，比如推特、服务器日志或者物联网设备。

数据源向你的接口发送数据，你的接口就会将数据保存在一个暂时的存储器中。

这个临时的存储器允许其他阶段快速便捷的访问数据。

一个好的方案就是使用消息队列系统，比如Apache Kafka、RabbitMQ或者AWS Kinesis。有时人们也会针对某些应用使用缓存，像Redis。

一种好用的实践是临时存储器遵循发布-订阅模式，这样API就可以发布消息，以便分析系统可以快速消费它们。

### 13.2 分析、处理

分析阶段是真正进行数据的地方。数据分析就是形成数据流并批量处理它们。

数据流来自摄入的数据，因此是实时的，并且能够快速出分析结果。

作为最重要最核心的阶段，数据分析会访问大数据存储系统，分析系统带走大批的数据并进行分析，这种类型的数据分析叫做批处理。它将为你解决很大的问题。

想学习更多关于流和批处理可以阅读我的博客文章：How to Create New and Exciting Big Data Aided Products

数据分析和流处理不是单向处理的过程，数据分析同样会写回数据到存储系统中。

通常将分析数据写入存储系统是有意义的，它允许你将之前的分析结果和原始数据结合起来。

如果将它们结合起来进行分析，也许会有意想不到的收获。

通常广泛使用的大数据分析工具如MapReduce或AWS Elastic MapReduce、Apache Spark以及AWS lambda。

### 13.3 存储

典型的大数据存储是储存所有的数据，这有助于你从大局上进行分析。

很多数据看似无用，但最重要的是保持它，千万不要丢弃数据。

为什么不能丢弃无用的数据？

虽然它现在看起来是没用的，数据科学家可以使用数据正常分析，但是他们今后有可能会从另外的角度去进行分析，并且能够得出有趣的观点，这个时候看似无用的数据就派上用场了。

什么样的系统可以用作大数据存储？

比如Hadoop HDFS、Hbase、Amazon S3或者DynamoDB都是可以完美适应大数据存储的系统。

我的播客中提到关于使用关系型数据库还是菲关系型数据库的问题： https://anchor.fm/andreaskayy/embed/episodes/NoSQL-Vs-SQL-How-To-Choose-e12f1o

### 13.4 展示

展示数据也是非常重要的一个环节。人们需要让大数据可以去驱动决策。

这就是为什么让数据可视化非常重要，有时你会有来自不同平台的案例和项目。

你可能无法构建每一个人都满意的UI，你可以做的是让他们自己去构建自己满意的UI。

怎么做？开放API去接收数据，允许他们开发。

无论是UI还是API，数据可视化的目的都是让展示阶段可以直接访问到大数据集群中的数据，这种对数据的访问允许开发者直接去使用数据分析的结果，以构建完美的应用程序。

## 14. Lamdba架构

（表 14.1）

### 14.1 批处理

问个大问题，记得你去年的纳税申请表吗？

你打开文件夹，在房间里到处找收据。

真是有趣的事情。

当你找到所有的东西，你填好表格，把它寄出去。

制作纳税表单的过程就是一个批处理的过程。

数据进去存储器，然后分析系统从存储器中加载数据，最后输出：

（图 14.1）

批处理就是你在没有计划和计划表的时候做一些事情。

它经常用来提出大问题，或者从大局上提出见解。

批处理工作就是使用大量的数据。这些数据可能来自Hadoop HDFS等。

它们可以没有问题的储存很多数据。

批处理工作的结果很有用，不过执行处理的时间可能会很长，毕竟数据量非常大。

它可能会花费你几分钟或者几个小时的时间。

### 14.2 流处理

及时了解你的数据。

流处理允许用户基于真实数据实时的得出结论或者做出行动。和批处理相比，流处理快到飞起。

用流处理你不需要等待数个小时才能得到结果，你可以立即得到数据的分析见解。

批处理进程中，数据分析总是落后于数据存储，需要获取所有可用的数据。

流处理可以在数据存储之前得到结果，它允许系统仅仅得到数据的某一部分。

也因此，得到的数据结果有限，毕竟大的蓝图受到限制。

（图 14.2）

仅使用流分析你就可以为用户提供先进的服务了。Netflix将流处理集成到Chuckwa V2.0和新的Keystone管道中。

一个使用流处理提供先进服务的例子就是Netflix的“Trending Now”特性。

### 14.3 你应该用流处理还是批处理？

开始的时候用批处理是一个好想法，批处理是每一个大数据平台的基础。

平台便捷也意味着，可以以较低的成本运行起来。

一个批处理平台可以帮助你快速的提出大问题，它可以针对你的顾客和数据提供给你无价的见解。

随着时间的流逝，你可能渐渐的需要让数据分析变得更快，这个时候再将流处理管道嫁到你的大数据平台批处理任务中。

### 14.4 Lambda架构的替代品

#### 14.4.1 Kappa架构

#### 14.4.2 带Kudu的Kappa架构

### 14.5 为什么一个好的大数据平台是重要的

（表 14.2）

## 15. Data Warehouse vs Data Lake

## 16. Hadoop平台 —— 可行

当人们谈论大数据的时候，第一个想到的就是Hadoop，谷歌一下Hadoop，大约有28百万条信息。

看起来你需要Hadoo去做大数据，今天我会阐明为什么Hadoop如此流行。

你会看到Hadoop从一个平台演化成一个生态系统，它的设计允许很多Apache项目和第三方工具从中受益。

我将以我的观点讲述它，如果你需要学习Hadoop，如果Hadoop是适合每个人的技术。

### 16.1 Hadoop是什么

Hadoop是一个针对分布式存储和大数据分析的平台。

Hadoop有4个主要模块：Hadoop common、JHDFS、MapReduce和YARN。这些模块被编织在一起就是Hadoop如此成功的原因。

Hadoop common的包和函数是在后台运行的，所以我没有深入了解它们，它们的作用是支持Hadoop模块的工作。

（表 16.1）

### 16.2 是什么让Hadoop如此流行 —— 可行

能够储存和分析大量数据当然是好的，但是为什么Hadoop会这么流行呢？

Hadoop的核心能力是Hadoop采用的驱动，很多Apache的其他项目都在用它的核心功能。

因为很多Hadoop的边缘项目都被算入Hadoop生态系统，一个做数据存储和数据分析的系统。

为了更好的看明白这个生态系统，我画了下面这个图。它展示了生态系统中与Hadoop紧密关联的项目。

它不是一个完整的列表，还有很多我不知道的工具，也许我以后可以画一个更完整的图。

（图 16.1）

### 16.3 Hadoop生态系统组件

还记得我的大数据蓝图吗？我的蓝图包含四个部分：摄入、储存、分析和展示。

正因为Hadoop生态系统，可以让这些阶段的工作完美协同起来。

例如：

（图 16.2）

使用Kafka摄取数据，用HDFS储存数据。用Apache Sprak做数据分析，并将显示结果作为后端储存在HBase中。

一个工作系统同样需要YARN做资源管理，你同样需要Zookeeper作为配置中心去管理kafka和HBase。

你可以在下面的图中看到每一个项目都和其它项目紧密联系。

Spark实例可以直接进入Kafka消费数据，它也可以进入HDFS对数据排序或者处理储存着的数据。

它也可以向HBase写入数据，将分析结果推送到前端。

这个生态系统最酷的一点是可以轻易的构建新的功能。

想要用Spark直接把Kafka的数据存到HDFS里面？

没问题，有一个项目叫Apache Flume就是干这个事的。

我可以作为一个代理去Kafka中消费消息，你甚至不需要担心Flume中的资源管理问题。

Flume可以直接调用Hadoop的YARN资源管理。

（图 16.3）

### 16.4 Hadoop无处不在？

Hadoop虽然很强大但它不是银弹，你也不能再任何场景都去用它。

通常部署一个Hadoop集群是没有意义的，因为它可能消耗过大。Hadoop不能运行在单个服务器上。

你可能需要至少5台服务器，最好6台以上，因此对于平台初期，成本是非常高的。


一种选择是你可以使用特殊的系统，比如Cassandra、MongoDB或者其他非关系型数据库去存储数据。或者你移步去Amazon使用Amazon的简单储存服务、S3等。

猜一猜S3背后的技术是什么？是的，HDFS，这就是为什么亚马逊有和MapReduce同等弹性的MapReduce。

使用S3最大的好处是你的系统可以从小开始，当你的系统逐渐壮大时，你也不需要考虑S3扩容的问题。

### 16.5 你应该学习Hadoop吗？

是的，我非常建议你去学习一下Hadoop的工作原理以及如何使用它，就像我在这篇文章中说的，它的生态系统很大。

很多大数据项目都使用Haddoop或者使用Hadoop的接口，这样你在学习Hadoop的过程中也可以学习到很多其他大数据相关的东西。

不需要特别深入，只要知道它们怎么工作，该如何去使用它们就够了。你的主要任务是当你进入一个大数据项目时，你可以快速前进。

另外，大多数相关的额技术都是开源的，你可以无偿使用它们。

**Hadoop系统的架构是什么样子**

**Hadoop集群常用的工具是什么**

Yarn Zookeeper HDFS Oozie Flume Hive

### 16.6 如何选择Hadoop硬件
